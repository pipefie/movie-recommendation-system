{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System (1M)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial library load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, Subset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "from datetime import datetime\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3fd8027450>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('runs'):\n",
    "    os.makedirs('runs')\n",
    "writer = SummaryWriter('runs/lenet5_mnist')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"./ml-1m/ratings.dat\", sep=\"::\", header=None,\n",
    "                      names=['UserID','MovieID','Rating','Timestamp'], engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert timestamp to datetime\n",
    "ratings['Datetime'] = ratings['Timestamp'].apply(lambda ts: datetime.fromtimestamp(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['Label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure user and movie IDs are zero-indexed for embedding layers.\n",
    "ratings['UserID'] = ratings['UserID'] - 1  # Users: 0 to 6039\n",
    "ratings['MovieID'] = ratings['MovieID'] - 1  # Movies: 0 to (n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "UserID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MovieID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Timestamp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "78770a7c-30f1-4834-9ebe-27cf177ecece",
       "rows": [
        [
         "0",
         "0",
         "1192",
         "5",
         "978300760",
         "2000-12-31 23:12:40",
         "1"
        ],
        [
         "1",
         "0",
         "660",
         "3",
         "978302109",
         "2000-12-31 23:35:09",
         "1"
        ],
        [
         "2",
         "0",
         "913",
         "3",
         "978301968",
         "2000-12-31 23:32:48",
         "1"
        ],
        [
         "3",
         "0",
         "3407",
         "4",
         "978300275",
         "2000-12-31 23:04:35",
         "1"
        ],
        [
         "4",
         "0",
         "2354",
         "5",
         "978824291",
         "2001-01-07 00:38:11",
         "1"
        ],
        [
         "5",
         "0",
         "1196",
         "3",
         "978302268",
         "2000-12-31 23:37:48",
         "1"
        ],
        [
         "6",
         "0",
         "1286",
         "5",
         "978302039",
         "2000-12-31 23:33:59",
         "1"
        ],
        [
         "7",
         "0",
         "2803",
         "5",
         "978300719",
         "2000-12-31 23:11:59",
         "1"
        ],
        [
         "8",
         "0",
         "593",
         "4",
         "978302268",
         "2000-12-31 23:37:48",
         "1"
        ],
        [
         "9",
         "0",
         "918",
         "4",
         "978301368",
         "2000-12-31 23:22:48",
         "1"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1192</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>2000-12-31 23:12:40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>660</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>2000-12-31 23:35:09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>913</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>2000-12-31 23:32:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3407</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>2000-12-31 23:04:35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2354</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>2001-01-07 00:38:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1196</td>\n",
       "      <td>3</td>\n",
       "      <td>978302268</td>\n",
       "      <td>2000-12-31 23:37:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1286</td>\n",
       "      <td>5</td>\n",
       "      <td>978302039</td>\n",
       "      <td>2000-12-31 23:33:59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2803</td>\n",
       "      <td>5</td>\n",
       "      <td>978300719</td>\n",
       "      <td>2000-12-31 23:11:59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>593</td>\n",
       "      <td>4</td>\n",
       "      <td>978302268</td>\n",
       "      <td>2000-12-31 23:37:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>918</td>\n",
       "      <td>4</td>\n",
       "      <td>978301368</td>\n",
       "      <td>2000-12-31 23:22:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp            Datetime  Label\n",
       "0       0     1192       5  978300760 2000-12-31 23:12:40      1\n",
       "1       0      660       3  978302109 2000-12-31 23:35:09      1\n",
       "2       0      913       3  978301968 2000-12-31 23:32:48      1\n",
       "3       0     3407       4  978300275 2000-12-31 23:04:35      1\n",
       "4       0     2354       5  978824291 2001-01-07 00:38:11      1\n",
       "5       0     1196       3  978302268 2000-12-31 23:37:48      1\n",
       "6       0     1286       5  978302039 2000-12-31 23:33:59      1\n",
       "7       0     2803       5  978300719 2000-12-31 23:11:59      1\n",
       "8       0      593       4  978302268 2000-12-31 23:37:48      1\n",
       "9       0      918       4  978301368 2000-12-31 23:22:48      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"./ml-1m/movies.dat\", sep=\"::\", header=None,\n",
    "                    names=['MovieID','Title','Genre'], engine=\"python\",\n",
    "                    encoding=\"utf-8\",\n",
    "                    lineterminator=\"\\n\",\n",
    "                    on_bad_lines=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MovieID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Genre",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3ac52805-cca1-492d-bf26-2fead67d11e9",
       "rows": [
        [
         "0",
         "1",
         "Toy Story (1995)",
         "Animation|Children's|Comedy"
        ],
        [
         "1",
         "2",
         "Jumanji (1995)",
         "Adventure|Children's|Fantasy"
        ],
        [
         "2",
         "3",
         "Grumpier Old Men (1995)",
         "Comedy|Romance"
        ],
        [
         "3",
         "4",
         "Waiting to Exhale (1995)",
         "Comedy|Drama"
        ],
        [
         "4",
         "5",
         "Father of the Bride Part II (1995)",
         "Comedy"
        ],
        [
         "5",
         "6",
         "Heat (1995)",
         "Action|Crime|Thriller"
        ],
        [
         "6",
         "7",
         "Sabrina (1995)",
         "Comedy|Romance"
        ],
        [
         "7",
         "8",
         "Tom and Huck (1995)",
         "Adventure|Children's"
        ],
        [
         "8",
         "9",
         "Sudden Death (1995)",
         "Action"
        ],
        [
         "9",
         "10",
         "GoldenEye (1995)",
         "Action|Adventure|Thriller"
        ],
        [
         "10",
         "11",
         "American President, The (1995)",
         "Comedy|Drama|Romance"
        ],
        [
         "11",
         "12",
         "Dracula: Dead and Loving It (1995)",
         "Comedy|Horror"
        ],
        [
         "12",
         "13",
         "Balto (1995)",
         "Animation|Children's"
        ],
        [
         "13",
         "14",
         "Nixon (1995)",
         "Drama"
        ],
        [
         "14",
         "15",
         "Cutthroat Island (1995)",
         "Action|Adventure|Romance"
        ],
        [
         "15",
         "16",
         "Casino (1995)",
         "Drama|Thriller"
        ],
        [
         "16",
         "17",
         "Sense and Sensibility (1995)",
         "Drama|Romance"
        ],
        [
         "17",
         "18",
         "Four Rooms (1995)",
         "Thriller"
        ],
        [
         "18",
         "19",
         "Ace Ventura: When Nature Calls (1995)",
         "Comedy"
        ],
        [
         "19",
         "20",
         "Money Train (1995)",
         "Action"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Tom and Huck (1995)</td>\n",
       "      <td>Adventure|Children's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sudden Death (1995)</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>American President, The (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Dracula: Dead and Loving It (1995)</td>\n",
       "      <td>Comedy|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Balto (1995)</td>\n",
       "      <td>Animation|Children's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Nixon (1995)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Cutthroat Island (1995)</td>\n",
       "      <td>Action|Adventure|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Casino (1995)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Ace Ventura: When Nature Calls (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Money Train (1995)</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MovieID                                  Title  \\\n",
       "0         1                       Toy Story (1995)   \n",
       "1         2                         Jumanji (1995)   \n",
       "2         3                Grumpier Old Men (1995)   \n",
       "3         4               Waiting to Exhale (1995)   \n",
       "4         5     Father of the Bride Part II (1995)   \n",
       "5         6                            Heat (1995)   \n",
       "6         7                         Sabrina (1995)   \n",
       "7         8                    Tom and Huck (1995)   \n",
       "8         9                    Sudden Death (1995)   \n",
       "9        10                       GoldenEye (1995)   \n",
       "10       11         American President, The (1995)   \n",
       "11       12     Dracula: Dead and Loving It (1995)   \n",
       "12       13                           Balto (1995)   \n",
       "13       14                           Nixon (1995)   \n",
       "14       15                Cutthroat Island (1995)   \n",
       "15       16                          Casino (1995)   \n",
       "16       17           Sense and Sensibility (1995)   \n",
       "17       18                      Four Rooms (1995)   \n",
       "18       19  Ace Ventura: When Nature Calls (1995)   \n",
       "19       20                     Money Train (1995)   \n",
       "\n",
       "                           Genre  \n",
       "0    Animation|Children's|Comedy  \n",
       "1   Adventure|Children's|Fantasy  \n",
       "2                 Comedy|Romance  \n",
       "3                   Comedy|Drama  \n",
       "4                         Comedy  \n",
       "5          Action|Crime|Thriller  \n",
       "6                 Comedy|Romance  \n",
       "7           Adventure|Children's  \n",
       "8                         Action  \n",
       "9      Action|Adventure|Thriller  \n",
       "10          Comedy|Drama|Romance  \n",
       "11                 Comedy|Horror  \n",
       "12          Animation|Children's  \n",
       "13                         Drama  \n",
       "14      Action|Adventure|Romance  \n",
       "15                Drama|Thriller  \n",
       "16                 Drama|Romance  \n",
       "17                      Thriller  \n",
       "18                        Comedy  \n",
       "19                        Action  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_norm = movies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_norm['Title'] = movies_norm['Title'].apply(lambda x: unidecode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_norm['Genre_List'] = movies_norm['Genre'].apply(lambda x: x.split('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MovieID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Genre",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Genre_List",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f551f2d3-e6f9-4a7e-8b61-6448d827323a",
       "rows": [
        [
         "0",
         "1",
         "Toy Story (1995)",
         "Animation|Children's|Comedy",
         "['Animation', \"Children's\", 'Comedy']"
        ],
        [
         "1",
         "2",
         "Jumanji (1995)",
         "Adventure|Children's|Fantasy",
         "['Adventure', \"Children's\", 'Fantasy']"
        ],
        [
         "2",
         "3",
         "Grumpier Old Men (1995)",
         "Comedy|Romance",
         "['Comedy', 'Romance']"
        ],
        [
         "3",
         "4",
         "Waiting to Exhale (1995)",
         "Comedy|Drama",
         "['Comedy', 'Drama']"
        ],
        [
         "4",
         "5",
         "Father of the Bride Part II (1995)",
         "Comedy",
         "['Comedy']"
        ],
        [
         "5",
         "6",
         "Heat (1995)",
         "Action|Crime|Thriller",
         "['Action', 'Crime', 'Thriller']"
        ],
        [
         "6",
         "7",
         "Sabrina (1995)",
         "Comedy|Romance",
         "['Comedy', 'Romance']"
        ],
        [
         "7",
         "8",
         "Tom and Huck (1995)",
         "Adventure|Children's",
         "['Adventure', \"Children's\"]"
        ],
        [
         "8",
         "9",
         "Sudden Death (1995)",
         "Action",
         "['Action']"
        ],
        [
         "9",
         "10",
         "GoldenEye (1995)",
         "Action|Adventure|Thriller",
         "['Action', 'Adventure', 'Thriller']"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Genre_List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>[Animation, Children's, Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "      <td>[Adventure, Children's, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>[Action, Crime, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Tom and Huck (1995)</td>\n",
       "      <td>Adventure|Children's</td>\n",
       "      <td>[Adventure, Children's]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sudden Death (1995)</td>\n",
       "      <td>Action</td>\n",
       "      <td>[Action]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>[Action, Adventure, Thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                               Title                         Genre  \\\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy   \n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy   \n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance   \n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama   \n",
       "4        5  Father of the Bride Part II (1995)                        Comedy   \n",
       "5        6                         Heat (1995)         Action|Crime|Thriller   \n",
       "6        7                      Sabrina (1995)                Comedy|Romance   \n",
       "7        8                 Tom and Huck (1995)          Adventure|Children's   \n",
       "8        9                 Sudden Death (1995)                        Action   \n",
       "9       10                    GoldenEye (1995)     Action|Adventure|Thriller   \n",
       "\n",
       "                         Genre_List  \n",
       "0   [Animation, Children's, Comedy]  \n",
       "1  [Adventure, Children's, Fantasy]  \n",
       "2                 [Comedy, Romance]  \n",
       "3                   [Comedy, Drama]  \n",
       "4                          [Comedy]  \n",
       "5         [Action, Crime, Thriller]  \n",
       "6                 [Comedy, Romance]  \n",
       "7           [Adventure, Children's]  \n",
       "8                          [Action]  \n",
       "9     [Action, Adventure, Thriller]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_norm.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"./ml-1m/users.dat\", sep=\"::\", engine=\"python\",\n",
    "                    header=None, names=['UserID','Gender','Age','Occupation','Zip-code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "UserID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Occupation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Zip-code",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c323b04b-179e-44e4-abbe-164c25e35c8e",
       "rows": [
        [
         "0",
         "1",
         "F",
         "1",
         "10",
         "48067"
        ],
        [
         "1",
         "2",
         "M",
         "56",
         "16",
         "70072"
        ],
        [
         "2",
         "3",
         "M",
         "25",
         "15",
         "55117"
        ],
        [
         "3",
         "4",
         "M",
         "45",
         "7",
         "02460"
        ],
        [
         "4",
         "5",
         "M",
         "25",
         "20",
         "55455"
        ],
        [
         "5",
         "6",
         "F",
         "50",
         "9",
         "55117"
        ],
        [
         "6",
         "7",
         "M",
         "35",
         "1",
         "06810"
        ],
        [
         "7",
         "8",
         "M",
         "25",
         "12",
         "11413"
        ],
        [
         "8",
         "9",
         "M",
         "25",
         "17",
         "61614"
        ],
        [
         "9",
         "10",
         "F",
         "35",
         "1",
         "95370"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Zip-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>F</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>06810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>11413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>61614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>95370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID Gender  Age  Occupation Zip-code\n",
       "0       1      F    1          10    48067\n",
       "1       2      M   56          16    70072\n",
       "2       3      M   25          15    55117\n",
       "3       4      M   45           7    02460\n",
       "4       5      M   25          20    55455\n",
       "5       6      F   50           9    55117\n",
       "6       7      M   35           1    06810\n",
       "7       8      M   25          12    11413\n",
       "8       9      M   25          17    61614\n",
       "9      10      F   35           1    95370"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test / Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_split(df):\n",
    "    # For each user, select the last interaction as test data.\n",
    "    df = df.sort_values(['UserID', 'Timestamp'])\n",
    "    test_list = df.groupby('UserID').tail(1)\n",
    "    train_df = df.drop(test_list.index)\n",
    "    return train_df, test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train+Validation samples: 994169\n",
      "Test samples: 6040\n"
     ]
    }
   ],
   "source": [
    "train_ratings_full, test_ratings = leave_one_out_split(ratings)\n",
    "print(\"Train+Validation samples:\", len(train_ratings_full))\n",
    "print(\"Test samples:\", len(test_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_train_val_split(df, val_frac=0.1, seed=seed):\n",
    "    train_idx = []\n",
    "    val_idx = []\n",
    "    np.random.seed(seed)\n",
    "    # Group by user and sample indices for validation per user.\n",
    "    for user, group in df.groupby('UserID'):\n",
    "        indices = group.index.tolist()\n",
    "        n_val = int(np.ceil(len(indices) * val_frac))\n",
    "        val_indices = np.random.choice(indices, size=n_val, replace=False)\n",
    "        train_indices = list(set(indices) - set(val_indices))\n",
    "        train_idx.extend(train_indices)\n",
    "        val_idx.extend(val_indices)\n",
    "    # Return DataFrames for train and validation splits.\n",
    "    train_df = df.loc[train_idx].reset_index(drop=True)\n",
    "    val_df = df.loc[val_idx].reset_index(drop=True)\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings, val_ratings = stratified_train_val_split(train_ratings_full, val_frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 892037\n",
      "Validation samples: 102132\n"
     ]
    }
   ],
   "source": [
    "print(\"Train samples:\", len(train_ratings))\n",
    "print(\"Validation samples:\", len(val_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Precompute User-Positive Movie Mapping for Negative Sampling\n",
    "# -------------------------\n",
    "\n",
    "def build_user_positive_dict(df):\n",
    "    return df.groupby('UserID')['MovieID'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_positive_train = build_user_positive_dict(train_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Sampling of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Custom Dataset with Negative Sampling (only for train and validation)\n",
    "# -------------------------\n",
    "\n",
    "class MovieLensDatasetWithNegatives(Dataset):\n",
    "    def __init__(self, df, user_positive, num_movies, num_negatives=4):\n",
    "        \"\"\"\n",
    "        df: DataFrame with positive interactions.\n",
    "        user_positive: Dictionary mapping user_id -> set of positive movie_ids.\n",
    "        num_movies: Total number of movies.\n",
    "        num_negatives: Number of negative samples to generate per positive instance.\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.user_positive = user_positive\n",
    "        self.num_movies = num_movies\n",
    "        self.num_negatives = num_negatives\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the positive sample.\n",
    "        user_id = int(self.df.loc[idx, 'UserID'])\n",
    "        pos_movie_id = int(self.df.loc[idx, 'MovieID'])\n",
    "        \n",
    "        # Start with the positive sample.\n",
    "        samples = [(user_id, pos_movie_id, 1)]\n",
    "        \n",
    "        # Generate negative samples for this user.\n",
    "        for _ in range(self.num_negatives):\n",
    "            neg_movie_id = random.randint(0, self.num_movies - 1)\n",
    "            while neg_movie_id in self.user_positive.get(user_id, set()):\n",
    "                neg_movie_id = random.randint(0, self.num_movies - 1)\n",
    "            samples.append((user_id, neg_movie_id, 0))\n",
    "        \n",
    "        # Return all samples (positive + negatives) for this positive instance.\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A collate function to flatten batches since __getitem__ returns a list of samples.\n",
    "def collate_fn(batch):\n",
    "    # batch is a list of lists (each element is a list of (user, movie, label) tuples)\n",
    "    flat_batch = [sample for sublist in batch for sample in sublist]\n",
    "    user_ids, movie_ids, labels = zip(*flat_batch)\n",
    "    return (torch.LongTensor(user_ids),\n",
    "            torch.LongTensor(movie_ids),\n",
    "            torch.FloatTensor(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = users['UserID'].nunique()\n",
    "## num_movies = movies_norm['MovieID'].nunique() creates an error becuase ids go up to 3951 but unique ids there's only 3883\n",
    "max_movie_id = ratings['MovieID'].max()\n",
    "num_movies = max_movie_id + 1\n",
    "batch_size = 256\n",
    "embedding_dim = 32  # Hyperparameter choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "train_dataset = MovieLensDatasetWithNegatives(train_ratings, user_positive_train, num_movies, num_negatives=4)\n",
    "val_dataset = MovieLensDatasetWithNegatives(val_ratings, build_user_positive_dict(val_ratings), num_movies, num_negatives=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing, we use only the positive interactions (held-out ones).\n",
    "class MovieLensTestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_ids = torch.LongTensor(df['UserID'].values)\n",
    "        self.movie_ids = torch.LongTensor(df['MovieID'].values)\n",
    "        self.labels = torch.FloatTensor(df['Label'].values)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.movie_ids[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MovieLensTestDataset(test_ratings)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ranking(model, dataset, device, K=10):\n",
    "    \"\"\"\n",
    "    Evaluates HR@K and NDCG@K on a dataset that returns\n",
    "    candidate sets (1 positive + multiple negatives).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    hr_sum = 0.0\n",
    "    ndcg_sum = 0.0\n",
    "    num_users = len(dataset)  # each __getitem__ is for one user (or one positive sample)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in range(num_users):\n",
    "            candidate_list = dataset[idx]  # e.g., [(user_id, pos_item, 1), (user_id, neg_item1, 0), ...]\n",
    "            \n",
    "            user_ids, item_ids, labels = zip(*candidate_list)\n",
    "            user_ids = torch.LongTensor(user_ids).to(device)\n",
    "            item_ids = torch.LongTensor(item_ids).to(device)\n",
    "            labels = torch.FloatTensor(labels).to(device)\n",
    "\n",
    "            # Predict scores for each candidate\n",
    "            scores = model(user_ids, item_ids).cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            \n",
    "            # Sort candidates by predicted score (descending)\n",
    "            sorted_indices = np.argsort(-scores)\n",
    "            \n",
    "            # Find the rank of the positive item\n",
    "            for rank, sorted_idx in enumerate(sorted_indices, start=1):\n",
    "                if labels[sorted_idx] == 1:\n",
    "                    # Hit Ratio\n",
    "                    if rank <= K:\n",
    "                        hr_sum += 1.0\n",
    "                        # NDCG\n",
    "                        ndcg_sum += 1.0 / np.log2(rank + 1)\n",
    "                    break\n",
    "    \n",
    "    hr_avg = hr_sum / num_users\n",
    "    ndcg_avg = ndcg_sum / num_users\n",
    "    return hr_avg, ndcg_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network architecture (GMF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://arxiv.org/pdf/1708.05031 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(GMF, self).__init__()\n",
    "        # Embedding layers for users and items\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        # Output layer weight (h) for combining element-wise product (Learnable weight vector)\n",
    "        self.h = nn.Parameter(torch.randn(embedding_dim))\n",
    "        # Sigmoid activation to map predictions to [0, 1]\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "      \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  \n",
    "        p_u = self.user_embedding(user_ids)  # shape: [batch_size, embedding_dim]\n",
    "        q_i = self.item_embedding(item_ids)  # shape: [batch_size, embedding_dim]\n",
    "        interaction = p_u * q_i              # Element-wise product\n",
    "        # Linear combination using the weight vector h\n",
    "        score = torch.sum(interaction * self.h, dim=1)  # Weighted sum\n",
    "        prediction = self.sigmoid(score)     # Map to [0, 1]\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GMF(num_users, num_movies, embedding_dim)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserID range: 0 6039\n",
      "MovieID range: 0 3951\n"
     ]
    }
   ],
   "source": [
    "print(\"UserID range:\", ratings['UserID'].min(), ratings['UserID'].max())\n",
    "print(\"MovieID range:\", ratings['MovieID'].min(), ratings['MovieID'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040\n",
      "3952\n"
     ]
    }
   ],
   "source": [
    "print(num_users)\n",
    "print(num_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training only for GMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 6.1076\n",
      "Epoch 1/10, Validation Loss: 3.6098\n",
      "Epoch 2/10, Train Loss: 3.4985\n",
      "Epoch 2/10, Validation Loss: 3.4664\n",
      "Epoch 3/10, Train Loss: 3.4660\n",
      "Epoch 3/10, Validation Loss: 3.4650\n",
      "Epoch 4/10, Train Loss: 3.2076\n",
      "Epoch 4/10, Validation Loss: 2.7234\n",
      "Epoch 5/10, Train Loss: 2.1992\n",
      "Epoch 5/10, Validation Loss: 2.1273\n",
      "Epoch 6/10, Train Loss: 1.8791\n",
      "Epoch 6/10, Validation Loss: 1.9733\n",
      "Epoch 7/10, Train Loss: 1.7879\n",
      "Epoch 7/10, Validation Loss: 1.9204\n",
      "Epoch 8/10, Train Loss: 1.7478\n",
      "Epoch 8/10, Validation Loss: 1.8964\n",
      "Epoch 9/10, Train Loss: 1.7114\n",
      "Epoch 9/10, Validation Loss: 1.8792\n",
      "Epoch 10/10, Train Loss: 1.6659\n",
      "Epoch 10/10, Validation Loss: 1.8632\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Training Loop with Validation\n",
    "# -------------------------\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for user_ids, movie_ids, labels in train_loader:\n",
    "        user_ids = user_ids.to(DEVICE)\n",
    "        movie_ids = movie_ids.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_ids, movie_ids)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * user_ids.size(0)\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_dataset)  # based on number of positive samples\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for user_ids, movie_ids, labels in val_loader:\n",
    "            user_ids = user_ids.to(DEVICE)\n",
    "            movie_ids = movie_ids.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            predictions = model(user_ids, movie_ids)\n",
    "            loss = criterion(predictions, labels)\n",
    "            val_loss += loss.item() * user_ids.size(0)\n",
    "    avg_val_loss = val_loss / len(val_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.1887\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Evaluation on Test Data\n",
    "# -------------------------\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for user_ids, movie_ids, labels in test_loader:\n",
    "        user_ids = user_ids.to(DEVICE)\n",
    "        movie_ids = movie_ids.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)       \n",
    "        \n",
    "        predictions = model(user_ids, movie_ids)\n",
    "        loss = criterion(predictions, labels)\n",
    "        test_loss += loss.item() * user_ids.size(0)\n",
    "avg_test_loss = test_loss / len(test_dataset)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation HR@10: 1.0000, NDCG@10: 0.8241\n"
     ]
    }
   ],
   "source": [
    "hr, ndcg = evaluate_ranking(model, val_dataset, DEVICE, K=10)\n",
    "print(f\"Validation HR@10: {hr:.4f}, NDCG@10: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with traditional MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_validation(model,\n",
    "                          train_loader,\n",
    "                          val_loader,\n",
    "                          val_dataset,\n",
    "                          device,\n",
    "                          epochs=10,\n",
    "                          lr=1e-2,\n",
    "                          neg_sampling_K=10):\n",
    "    \"\"\"\n",
    "    Trains `model` for `epochs`, logging:\n",
    "      - avg BCE loss on training set\n",
    "      - avg BCE loss on validation loader\n",
    "      - HR@K and NDCG@K on val_dataset (for ranking)\n",
    "    Returns a dict with keys:\n",
    "      'train_loss', 'val_loss', 'val_hr', 'val_ndcg'\n",
    "    \"\"\"\n",
    "    # 1. Prepare\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn   = nn.BCELoss()\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss':   [],\n",
    "        'val_hr':     [],\n",
    "        'val_ndcg':   []\n",
    "    }\n",
    "    # 2. Epoch loop\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        # 2a. Training\n",
    "        for user_ids, movie_ids, labels in train_loader:\n",
    "            user_ids = user_ids.to(DEVICE)\n",
    "            movie_ids = movie_ids.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(user_ids, movie_ids)\n",
    "            loss = loss_fn(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * user_ids.size(0)\n",
    "    \n",
    "        avg_train_loss = epoch_loss / len(train_loader.dataset)  # based on number of positive samples\n",
    "        # ---------- Validation Loss ----------\n",
    "        # 2b. Validation (ranking)\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for user_ids, movie_ids, labels in val_loader:\n",
    "                user_ids = user_ids.to(DEVICE)\n",
    "                movie_ids = movie_ids.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                \n",
    "                predictions = model(user_ids, movie_ids)\n",
    "                loss = loss_fn(predictions, labels)\n",
    "                val_loss += loss.item() * user_ids.size(0)\n",
    "        avg_val_loss = val_loss / len(val_dataset)\n",
    "\n",
    "        # ---------- Ranking Metrics on val_dataset ----------\n",
    "        hr, ndcg = evaluate_ranking(model, val_dataset, device, K=neg_sampling_K)\n",
    "\n",
    "        # ---------- Logging ----------\n",
    "        print(f\"Epoch {epoch}/{epochs}  \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f}  \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}  \"\n",
    "              f\"HR@{K}: {hr:.4f}  \"\n",
    "              f\"NDCG@{K}: {ndcg:.4f}\")\n",
    "\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss']  .append(avg_val_loss)\n",
    "        history['val_hr']    .append(hr)\n",
    "        history['val_ndcg']  .append(ndcg)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(MF, self).__init__()\n",
    "        # Embeddings exactly like GMF\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        # No learnable h vector here\n",
    "    \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        p_u = self.user_embedding(user_ids)  # [B, K]\n",
    "        q_i = self.item_embedding(item_ids)  # [B, K]\n",
    "        # Classic inner-product\n",
    "        score = (p_u * q_i).sum(dim=1)       # [B]\n",
    "        # If using implicit feedback + BCE, pass through sigmoid:\n",
    "        return torch.sigmoid(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training MF ---\n",
      "Epoch 1/5  Train Loss: 9.9897  Val Loss: 8.0585  HR@10: 1.0000  NDCG@10: 0.5886\n",
      "Epoch 2/5  Train Loss: 6.5507  Val Loss: 5.2933  HR@10: 1.0000  NDCG@10: 0.6084\n",
      "Epoch 3/5  Train Loss: 3.7962  Val Loss: 2.9333  HR@10: 1.0000  NDCG@10: 0.7274\n",
      "Epoch 4/5  Train Loss: 2.2783  Val Loss: 2.2476  HR@10: 1.0000  NDCG@10: 0.7825\n",
      "Epoch 5/5  Train Loss: 1.9013  Val Loss: 2.0368  HR@10: 1.0000  NDCG@10: 0.8029\n",
      "\n",
      "--- Training GMF ---\n",
      "Epoch 1/5  Train Loss: 5.6648  Val Loss: 3.4807  HR@10: 1.0000  NDCG@10: 0.5875\n",
      "Epoch 2/5  Train Loss: 3.4676  Val Loss: 3.4665  HR@10: 1.0000  NDCG@10: 0.5897\n",
      "Epoch 3/5  Train Loss: 3.4651  Val Loss: 3.4564  HR@10: 1.0000  NDCG@10: 0.5987\n",
      "Epoch 4/5  Train Loss: 3.0116  Val Loss: 2.5453  HR@10: 1.0000  NDCG@10: 0.7484\n",
      "Epoch 5/5  Train Loss: 2.1176  Val Loss: 2.0937  HR@10: 1.0000  NDCG@10: 0.7979\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 5\n",
    "lr     = 1e-3\n",
    "K      = 10\n",
    "\n",
    "# 1) Compare MF\n",
    "mf = MF(num_users, num_movies, embedding_dim)\n",
    "print(\"\\n--- Training MF ---\")\n",
    "hist_mf = train_with_validation(\n",
    "    mf,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    val_dataset,\n",
    "    DEVICE,\n",
    "    epochs=epochs,\n",
    "    lr=lr,\n",
    "    neg_sampling_K=K\n",
    ")\n",
    "\n",
    "# 2) Compare GMF\n",
    "gmf = GMF(num_users, num_movies, embedding_dim)\n",
    "print(\"\\n--- Training GMF ---\")\n",
    "hist_gmf = train_with_validation(\n",
    "    gmf,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    val_dataset,\n",
    "    DEVICE,\n",
    "    epochs=epochs,\n",
    "    lr=lr,\n",
    "    neg_sampling_K=K\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pipe/venv/deepLearningvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-04-27 21:50:02,285] A new study created in memory with name: no-name-0d480fd5-da6c-4735-bd33-0b68ec4a808a\n",
      "[I 2025-04-27 21:52:53,076] Trial 0 finished with values: [0.4126032123796127, -0.822522603190414] and parameters: {'embedding_dim': 64, 'lr': 0.0026232317154338504, 'neg_ratio': 3}.\n",
      "[I 2025-04-27 21:55:52,651] Trial 1 finished with values: [0.3834005135949311, -0.8137022808201813] and parameters: {'embedding_dim': 16, 'lr': 0.0018567045923492092, 'neg_ratio': 4}.\n",
      "[I 2025-04-27 21:58:42,992] Trial 2 finished with values: [0.6442792700674439, -0.6509073654097698] and parameters: {'embedding_dim': 128, 'lr': 0.0005588007131489181, 'neg_ratio': 4}.\n",
      "[I 2025-04-27 22:01:42,102] Trial 3 finished with values: [0.6111817945582613, -0.6869701549432307] and parameters: {'embedding_dim': 16, 'lr': 0.00043130822749060105, 'neg_ratio': 4}.\n",
      "[I 2025-04-27 22:04:40,743] Trial 4 finished with values: [0.3419016402443684, -0.8198337464499664] and parameters: {'embedding_dim': 64, 'lr': 0.0018852485522881516, 'neg_ratio': 5}.\n",
      "[I 2025-04-27 22:07:49,264] Trial 5 finished with values: [0.27446849833797055, -0.8507463853175136] and parameters: {'embedding_dim': 16, 'lr': 0.004217344538619473, 'neg_ratio': 7}.\n",
      "[I 2025-04-27 22:10:52,427] Trial 6 finished with values: [0.2915426412643914, -0.8525645455939866] and parameters: {'embedding_dim': 128, 'lr': 0.006242866395545031, 'neg_ratio': 7}.\n",
      "[I 2025-04-27 22:13:46,203] Trial 7 finished with values: [0.692482377181335, -0.5957527383989845] and parameters: {'embedding_dim': 16, 'lr': 0.0004730154388191377, 'neg_ratio': 4}.\n",
      "[I 2025-04-27 22:16:57,770] Trial 8 finished with values: [0.4306704751572056, -0.7744795925484114] and parameters: {'embedding_dim': 16, 'lr': 0.0008849300631774328, 'neg_ratio': 5}.\n",
      "[I 2025-04-27 22:19:51,164] Trial 9 finished with values: [0.41184709405280895, -0.8246793296210895] and parameters: {'embedding_dim': 128, 'lr': 0.002440384508755325, 'neg_ratio': 3}.\n",
      "[I 2025-04-27 22:23:05,316] Trial 10 finished with values: [0.29054415641742165, -0.8561847563600465] and parameters: {'embedding_dim': 16, 'lr': 0.004475592325958436, 'neg_ratio': 6}.\n",
      "[I 2025-04-27 22:26:07,248] Trial 11 finished with values: [0.7368978491957644, -0.5891776721224875] and parameters: {'embedding_dim': 64, 'lr': 0.00011792499658268677, 'neg_ratio': 6}.\n",
      "[I 2025-04-27 22:28:53,156] Trial 12 finished with values: [0.6932324138641245, -0.5891257480607641] and parameters: {'embedding_dim': 32, 'lr': 0.00034702945771105336, 'neg_ratio': 3}.\n",
      "[I 2025-04-27 22:31:50,956] Trial 13 finished with values: [0.33981579644057297, -0.8233695491788827] and parameters: {'embedding_dim': 32, 'lr': 0.002222912602544727, 'neg_ratio': 5}.\n",
      "[I 2025-04-27 22:34:40,171] Trial 14 finished with values: [0.6848132855294664, -0.6135670343931333] and parameters: {'embedding_dim': 16, 'lr': 0.0004337958159263349, 'neg_ratio': 4}.\n",
      "[I 2025-04-27 22:37:15,283] Trial 15 finished with values: [0.4676619084333881, -0.8147644788890315] and parameters: {'embedding_dim': 64, 'lr': 0.0023395988246935535, 'neg_ratio': 2}.\n",
      "[I 2025-04-27 22:40:17,782] Trial 16 finished with values: [0.26816794184961823, -0.8295817727538515] and parameters: {'embedding_dim': 64, 'lr': 0.0024276509208660843, 'neg_ratio': 8}.\n",
      "[I 2025-04-27 22:43:11,984] Trial 17 finished with values: [0.6982491132501794, -0.588272323431822] and parameters: {'embedding_dim': 32, 'lr': 0.00014385861402995074, 'neg_ratio': 4}.\n",
      "[I 2025-04-27 22:46:24,254] Trial 18 finished with values: [0.6931152323090418, -0.5902018210865153] and parameters: {'embedding_dim': 16, 'lr': 0.00020503694474735329, 'neg_ratio': 7}.\n",
      "[I 2025-04-27 22:49:14,354] Trial 19 finished with values: [0.37645341052257536, -0.818116947941565] and parameters: {'embedding_dim': 64, 'lr': 0.0019866169938729814, 'neg_ratio': 4}.\n",
      "[I 2025-04-27 22:52:06,866] Trial 20 finished with values: [0.36432068133071255, -0.853038784765365] and parameters: {'embedding_dim': 128, 'lr': 0.009079213965033061, 'neg_ratio': 4}.\n",
      "[I 2025-04-27 22:55:03,951] Trial 21 finished with values: [0.6944034462557208, -0.5888269063576999] and parameters: {'embedding_dim': 64, 'lr': 0.0001496516923628374, 'neg_ratio': 6}.\n",
      "[I 2025-04-27 22:57:57,958] Trial 22 finished with values: [0.6958129811673506, -0.5885596220471414] and parameters: {'embedding_dim': 32, 'lr': 0.00012359322617768497, 'neg_ratio': 5}.\n",
      "[I 2025-04-27 23:00:54,923] Trial 23 finished with values: [0.5835484229514075, -0.7044991889565455] and parameters: {'embedding_dim': 16, 'lr': 0.0008059214506221757, 'neg_ratio': 4}.\n",
      "[I 2025-04-27 23:04:12,086] Trial 24 finished with values: [0.29212040172589493, -0.8195380110885211] and parameters: {'embedding_dim': 16, 'lr': 0.0019571487312013943, 'neg_ratio': 7}.\n",
      "[I 2025-04-27 23:07:19,599] Trial 25 finished with values: [0.3103208170557902, -0.82923451036573] and parameters: {'embedding_dim': 32, 'lr': 0.0028303416154259633, 'neg_ratio': 6}.\n",
      "[I 2025-04-27 23:10:03,654] Trial 26 finished with values: [0.6931691641757693, -0.5893275431364912] and parameters: {'embedding_dim': 16, 'lr': 0.00042100859278343893, 'neg_ratio': 2}.\n",
      "[I 2025-04-27 23:13:10,117] Trial 27 finished with values: [0.2981823145635903, -0.813911394274626] and parameters: {'embedding_dim': 16, 'lr': 0.0013669919238958612, 'neg_ratio': 7}.\n",
      "[I 2025-04-27 23:16:16,439] Trial 28 finished with values: [0.432550082635605, -0.7274396580852742] and parameters: {'embedding_dim': 16, 'lr': 0.0004971062989272063, 'neg_ratio': 8}.\n",
      "[I 2025-04-27 23:18:50,594] Trial 29 finished with values: [0.46869522644789685, -0.8130484256170211] and parameters: {'embedding_dim': 128, 'lr': 0.002084938551816036, 'neg_ratio': 2}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pareto front (val_loss, -ndcg) and params:\n",
      "  values=[0.27446849833797055, -0.8507463853175136], params={'embedding_dim': 16, 'lr': 0.004217344538619473, 'neg_ratio': 7}\n",
      "  values=[0.29054415641742165, -0.8561847563600465], params={'embedding_dim': 16, 'lr': 0.004475592325958436, 'neg_ratio': 6}\n",
      "  values=[0.26816794184961823, -0.8295817727538515], params={'embedding_dim': 64, 'lr': 0.0024276509208660843, 'neg_ratio': 8}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # 1) Suggest hyperparameters\n",
    "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [16, 32, 64, 128])\n",
    "    lr            = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    neg_ratio     = trial.suggest_int(\"neg_ratio\", 2, 8)\n",
    "    \n",
    "    # 2) Build dataset & loaders\n",
    "    train_ds = MovieLensDatasetWithNegatives(\n",
    "        train_ratings,\n",
    "        user_positive_train,\n",
    "        num_movies,\n",
    "        num_negatives=neg_ratio\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=256, shuffle=True, collate_fn=collate_fn\n",
    "    )\n",
    "    # Validation loader for loss\n",
    "    val_loader = DataLoader(\n",
    "        MovieLensDatasetWithNegatives(\n",
    "            val_ratings,                # your peruser stratified val set\n",
    "            build_user_positive_dict(val_ratings),\n",
    "            num_movies,\n",
    "            num_negatives=neg_ratio     # or a fixed neg sampling for val\n",
    "        ),\n",
    "        batch_size=256,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    # 3) Build model, loss, optimizer\n",
    "    model     = GMF(num_users, num_movies, embedding_dim).to(DEVICE)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # 4) Training loop\n",
    "    num_epochs = 5\n",
    "    for _ in range(num_epochs):\n",
    "        model.train()\n",
    "        for u, i, y in train_loader:\n",
    "            u, i, y = u.to(DEVICE), i.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(u, i)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # 5) Validation loss\n",
    "    model.eval()\n",
    "    val_loss, val_count = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for u, i, y in val_loader:\n",
    "            u, i, y = u.to(DEVICE), i.to(DEVICE), y.to(DEVICE)\n",
    "            pred = model(u, i)\n",
    "            l = criterion(pred, y)\n",
    "            val_loss  += l.item() * u.size(0)\n",
    "            val_count += u.size(0)\n",
    "    avg_val_loss = val_loss / val_count\n",
    "    \n",
    "    # 6) Ranking metric (NDCG@10) on the held-out leave-one-out val_dataset\n",
    "    hr, ndcg = evaluate_ranking(model, val_dataset, DEVICE, K=10)\n",
    "    \n",
    "    # 7) Return the two objectives:\n",
    "    #    1) avg_val_loss to minimize\n",
    "    #    2) -ndcg       to minimize (i.e. maximize ndcg)\n",
    "    return avg_val_loss, -ndcg\n",
    "\n",
    "# Create a multi-objective study: minimize both objectives\n",
    "study = optuna.create_study(directions=[\"minimize\", \"minimize\"])\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Print Pareto-optimal trials\n",
    "print(\"Pareto front (val_loss, -ndcg) and params:\")\n",
    "for t in study.best_trials:\n",
    "    print(f\"  values={t.values}, params={t.params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test with the best parameters (from optuna study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = GMF(num_users, num_movies, embedding_dim=16)\n",
    "model_best = model_best.to(DEVICE)\n",
    "criterion_best = nn.BCELoss()\n",
    "optimizer_best = optim.Adam(model_best.parameters(), lr=0.004217344538619473)\n",
    "\n",
    "# Rebuild your dataset with the chosen negative sampling ratio\n",
    "train_dataset_best = MovieLensDatasetWithNegatives(\n",
    "    train_ratings,\n",
    "    user_positive_train,\n",
    "    num_movies,\n",
    "    num_negatives=7\n",
    ")\n",
    "train_loader_best = DataLoader(train_dataset_best, batch_size=256, shuffle=True, collate_fn=collate_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 5.6443\n",
      "Epoch 1/10, Validation Loss: 2.4885\n",
      "Epoch 2/10, Train Loss: 2.3988\n",
      "Epoch 2/10, Validation Loss: 1.9487\n",
      "Epoch 3/10, Train Loss: 2.1848\n",
      "Epoch 3/10, Validation Loss: 1.9250\n",
      "Epoch 4/10, Train Loss: 2.0884\n",
      "Epoch 4/10, Validation Loss: 1.8170\n",
      "Epoch 5/10, Train Loss: 1.9081\n",
      "Epoch 5/10, Validation Loss: 1.7429\n",
      "Epoch 6/10, Train Loss: 1.7835\n",
      "Epoch 6/10, Validation Loss: 1.6983\n",
      "Epoch 7/10, Train Loss: 1.7065\n",
      "Epoch 7/10, Validation Loss: 1.6797\n",
      "Epoch 8/10, Train Loss: 1.6586\n",
      "Epoch 8/10, Validation Loss: 1.6682\n",
      "Epoch 9/10, Train Loss: 1.6287\n",
      "Epoch 9/10, Validation Loss: 1.6540\n",
      "Epoch 10/10, Train Loss: 1.6072\n",
      "Epoch 10/10, Validation Loss: 1.6600\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Training Loop with Validation\n",
    "# -------------------------\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_best.train()\n",
    "    epoch_loss = 0.0\n",
    "    for user_ids, movie_ids, labels in train_loader_best:\n",
    "        user_ids = user_ids.to(DEVICE)\n",
    "        movie_ids = movie_ids.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        optimizer_best.zero_grad()\n",
    "        predictions = model_best(user_ids, movie_ids)\n",
    "        loss = criterion_best(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer_best.step()\n",
    "        epoch_loss += loss.item() * user_ids.size(0)\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_dataset)  # based on number of positive samples\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Validation step\n",
    "    model_best.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for user_ids, movie_ids, labels in val_loader:\n",
    "            user_ids = user_ids.to(DEVICE)\n",
    "            movie_ids = movie_ids.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            predictions = model_best(user_ids, movie_ids)\n",
    "            loss = criterion_best(predictions, labels)\n",
    "            val_loss += loss.item() * user_ids.size(0)\n",
    "    avg_val_loss = val_loss / len(val_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {avg_val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearningvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
